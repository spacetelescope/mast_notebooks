{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roman Engineering Data Retrieval\n",
    "\n",
    "------------------\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "- Understand how to programmatically access Roman Engineering Database (EDB) products (by mnemonic and date).\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#Introduction)\n",
    "* [Imports](#Imports)\n",
    "* [Helper Script](#Helper-Script)\n",
    "* [Downloading Data](#Downloading-Data)\n",
    "    * [Define the attributes for the mnemonics of interest](#Define-Mnemonic-Parameters) \n",
    "    * [Construct the filenames to contain the mnemonic timeseries](#Construct-File-Names)\n",
    "    * [Call the web service to fetch the data and return files containing the timeseries](#Call-the-Webservice)\n",
    "    * [Prepare the data for analysis](#Prepare-the-Data-for-Analysis)\n",
    "* [Visualize the data](#Visualize-the-Data-Tuple)\n",
    "    * [Split the data into mini-series at time boundaries](#Identify-Subseries-in-the-Data)\n",
    "    * [Plot the timeseries](#Plot-the-Segmented-Timeseries)\n",
    "* [Additional resources](#Additional-Resources)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates how to retrieve Roman engineeering data and use it in the context of a Python session.\n",
    "\n",
    "The [Roman Engineering Data](https://outerspace.stsci.edu/spaces/RAPD/pages/301172598/Search+for+Calibrated+Engineering+Data) tutorial in the Roman Pre-Launch documentation (restricted access pre-launch) describes how to access engineering telemetry points stored in the Roman Engineering Database in the form of timeseries. These data may be searched by means of an identifier, or **mnenomic**.\n",
    "\n",
    "Some quantities of interest require more than one mnemonic (a *tuple*) for meaningful analysis. This tutorial illustrates how to retrieve a tuple of mnenomics and visualize the result. In the following example, timeseries will be retrieved for mnemonics`SCF_AC_SDR_QBJ_`**n**, with **n** values of 1 through 4, which are the spacecraft orientation quaternion paremters.\n",
    "\n",
    "For more details on constructing a mnemonic, see the [Roman Engineering Data](https://outerspace.stsci.edu/spaces/RAPD/pages/301172598/Search+for+Calibrated+Engineering+Data) page (and also the [JWST Engineering Data](https://outerspace.stsci.edu/display/MASTDOCS/Engineering+Data) page, for general information on engineering database contents and mnemonic conventions, as similar layouts and conventions are used for both JWST and Roman).\n",
    "\n",
    "Note that this folder includes a companion script; after completing the tutorial, this offers a compact, customizable way to download the data.\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"color:black; border-color:teal;\">\n",
    "Please note that pre-launch, <b>the MAST Roman EDP Search API requires authorization to search and download Roman data products.</b> Before we get started, please ensure that:\n",
    "    \n",
    "- ***you are authorized to search and download Roman engineering data from MAST.*** If you are not authorized but you think you should be, email the helpdesk at archive@stsci.edu\n",
    "- ***you have a [MAST token](https://auth.mast.stsci.edu/token) set to the environment variable*** **`MAST_API_TOKEN`**\n",
    "</div>\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"color:black; background-color:#ffc5c5; border-color:red;\">\n",
    "<b>Note:</b> At this time, Roman data are not accessible from the cloud. Downloads will come from MAST servers and <b>may be large</b>. Download with caution.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This notebook uses the following packages to retreive data: \n",
    "\n",
    "* `os` to get MAST API token envirnoment variable, and for handling file separators, i.e. \"/\" on Unix-like machines and \"\\\\\" on Windows\n",
    "* `urllib` to complete the web request\n",
    "* `datetime` for manipulating datetime strings\n",
    "* `pathlib` to create a directory for the downloaded files\n",
    "* `numpy` and `pandas` for convenient data manipulation\n",
    "\n",
    "Additional packages are used for data visualization:\n",
    "\n",
    "* `bokeh` (`output_notebook`, `plotting`, `ColorBar`, `FixedTicker`, `Span`, `palette.Spectral10`, `linear_cmap`, `gridplot`) for plotting\n",
    "* `astropy.time.Time` to obtain MJD from ISO time formatted strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import ColorBar, FixedTicker, Span\n",
    "from bokeh.palettes import Spectral10 as cm\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "from astropy.time import Time  # To get datetimes in MJD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Script\n",
    "\n",
    "Below is a function to connect to the EDB web service and retrieve the data files. It will be used later in this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnemonic_datetimes_from_filename(fname):\n",
    "    splt = fname.split(\".\")[0].split('_')\n",
    "    mnemonic = '_'.join(splt[:-2])\n",
    "    s_time = datetime.fromisoformat(splt[-2]).isoformat()\n",
    "    e_time = datetime.fromisoformat(splt[-1]).isoformat()\n",
    "\n",
    "    return mnemonic, s_time, e_time\n",
    "\n",
    "\n",
    "def download_edb_datafiles(filenames, folder):\n",
    "    '''\n",
    "    Download filenames to directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filenames : iterable\n",
    "        List of string-valued file names to contain the desired mnemonic timeseries\n",
    "    folder: str\n",
    "        Directory (relative to cwd) in which to write output files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "       Success status for each mnemonic retrieval\n",
    "    '''\n",
    "            \n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    \n",
    "    mast_token = os.getenv(\"MAST_API_TOKEN\")\n",
    "    headers = {\n",
    "        \"Authorization\": f'token {mast_token}'\n",
    "    }\n",
    "\n",
    "    urlStr = 'https://mast.stsci.edu/edp/api/v0.1/mnemonics/spa/roman/data?mnemonic={}&s_time={}&e_time={}&result_format=csv' \n",
    "    status = 0\n",
    "\n",
    "    for fname in filenames:\n",
    "        print(\n",
    "            f\"Downloading File: mast:romanedb/{fname}\\n\",\n",
    "            f\" To: {folder}/{fname}\",\n",
    "        )\n",
    "        \n",
    "        mnemonic, s_time, e_time = get_mnemonic_datetimes_from_filename(fname)\n",
    "        url = urlStr.format(mnemonic, s_time, e_time)\n",
    "        req = urllib.request.Request(url, headers=headers)\n",
    "        \n",
    "        try:\n",
    "            # Open the URL with the request object and save to file\n",
    "            with urllib.request.urlopen(req) as response:\n",
    "                data = response.read().decode('utf-8')\n",
    "                with open(f\"{folder}/{fname}\", \"w\", encoding='utf-8') as f:\n",
    "                    f.write(data)\n",
    "        except urllib.error.URLError:\n",
    "            print(\"  ***Error downloading file***\")\n",
    "            status = 1\n",
    "    \n",
    "    return status  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "To download data, you'll need to format the request correctly. That requires defining mnemonics, naming files to match, and then calling the webservice to begin the download.\n",
    "\n",
    "### Define Mnemonic Parameters\n",
    "\n",
    "Next, define the parameters of each mnemonic of interest. The parameters are:\n",
    "* The mnenomic name\n",
    "* Start time\n",
    "* End time\n",
    "\n",
    "The start and end times are in UTC and have a \"compact\" ISO-8601 formatting: `yyyymmddThhmmss`, where the **T** is a literal character. The definitions can be stored in multiple ways: here they will be stored in a Python dictionary, which could be stored in an external `.yaml` file. In the companion script they are stored in an external `.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mnemonics of interest are a tuple, the start/end times are the same: from 00:00:00 on 2027 March 14 to 23:59:59 on 2027 March 16. Define these times first, followed by the full parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = { \n",
    "         't_start': '20270314T000000',\n",
    "         't_end':   '20270316T235959'\n",
    "        }\n",
    "mnemonics = {\n",
    "            'SCF_AC_SDR_QBJ_1': times,\n",
    "            'SCF_AC_SDR_QBJ_2': times,\n",
    "            'SCF_AC_SDR_QBJ_3': times,\n",
    "            'SCF_AC_SDR_QBJ_4': times\n",
    "           }\n",
    "for m, v in mnemonics.items():\n",
    "    print(m, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct File Names\n",
    "\n",
    "The key to fetching data from the web service is to construct file names to contain the data for each mnemonic. The web service will parse the file names to determine how to query the engineering database and retrieve the timeseries of interest.\n",
    "\n",
    "The file names have the form: \n",
    "\n",
    "    `<mnemonic_name>_<t_start>_<t_end>.csv`\n",
    "    \n",
    "Use a dictionary comprehension to construct a list of file names; these will be passed to the webservice calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['_'.join([m, v['t_start'], v['t_end']]) + '.csv' for m, v in mnemonics.items()]\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the (optional) output folder name prior to the webservice call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-directory where the data files will be written:\n",
    "subdir = 'edb-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the EDB web service. The files containing data will be written to your local storage, in the specified subdirectory. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:black\">\n",
    "    The webservice may take a long time (or timeout), depending upon the quantity of data in the timeseries within the chosen date range.\n",
    "    \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = download_edb_datafiles(fnames, folder=subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for Analysis\n",
    "\n",
    "Create a list of Pandas dataframes from the mnemonics data that were just written to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [pd.read_csv(subdir+os.path.sep+f) for f in fnames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the sizes of the dataframes are equal, and take a look at the first dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataframes have the same size? {}'.format(len(df[0]) == len(df[1])))\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data Tuples\n",
    "\n",
    "Create a series of joint plots (of each quaterion parameter against the others) for analysis. This is easy to do by plotting the Pandas dataframes. It is more interesting to add color to indicate changes in the spacecraft quaternion parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following method is needed for bokeh display in a Notebook.\n",
    "# Note that it does not activate the display. This happens in the 'Plot Timeseries' section.\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Subseries in the Data\n",
    "\n",
    "Engineering data may contain periods of sampling between observations where the returned values do not change. The following function attempts to break up the timeseries by looking for these stretches of unchanging values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_breaks(data_series, max_flats=5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_series : list of pandas.DataFrame\n",
    "        List of timeseries data.\n",
    "    max_flats : int, default=5\n",
    "        After this many data points with unchanging values, timeseries data will be broken up.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of pandas.DataFrame\n",
    "        Each DataFrame contains a continuous set of changing EDB timeseries data with grouped tuples of values from the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    vals_list = []\n",
    "    dates_list = []\n",
    "    for ds in data_series:\n",
    "        # Get the MJD and position values out of the DataFrames.\n",
    "        # ObsTime needs to be converted to a string and then coverted to MJD\n",
    "        vals_list.append(ds['EUValue'].values)\n",
    "        dates_list.append(Time(np.array(ds['ObsTime'].values, dtype=str), format='isot').mjd)\n",
    "    \n",
    "    # Combine the individual series into a single DataFrame.\n",
    "    combo_frame = pd.DataFrame(data=dates_list[0], columns=['MJD'])\n",
    "    combo_frame['timestamp'] = np.array(data_series[0]['ObsTime'].values, dtype=str)\n",
    "    for i, val_list in enumerate(vals_list):\n",
    "        combo_frame[f'value_{i+1}'] = val_list\n",
    "\n",
    "    # If only 1 timepoint, skip sampling breaks checking.\n",
    "    if len(vals_list[0]) == 1:\n",
    "        return [combo_frame]\n",
    "    \n",
    "    # Scan the timeseries data to look for flat periods of no reading change.\n",
    "    results = []\n",
    "    m = 0\n",
    "    flat = 0\n",
    "    recording = True\n",
    "    \n",
    "    for n in range(1, len(vals_list[0])):\n",
    "\n",
    "        # Make sure timestamps match: \n",
    "        dates_match = []\n",
    "        for j in range(len(dates_list)):\n",
    "            if j == 0:\n",
    "                date_ref = dates_list[j][n]\n",
    "            dates_match.append(dates_list[j][n] == date_ref)\n",
    "        if np.all(dates_match):\n",
    "            # Calculate the distance from the current positions to the following.\n",
    "            val_diffs = []\n",
    "            for j in range(len(dates_list)):\n",
    "                val_diffs.append(np.abs(vals_list[j][n-1] - vals_list[j][n]))\n",
    "\n",
    "            # Multiple points with no change will stop recording and store the current series.\n",
    "            if np.all(np.array(val_diffs) == 0):\n",
    "                flat += 1\n",
    "                if not recording:\n",
    "                    continue\n",
    "                elif flat >= max_flats:\n",
    "                    size = (n-max_flats) - m\n",
    "                    if size > 1:\n",
    "                        results.append(combo_frame[m:n-(max_flats)])\n",
    "                    recording = False\n",
    "                    \n",
    "            # Start recording if changes detected.\n",
    "            elif np.any(val_diffs > 0) and not recording:\n",
    "                flat = 0\n",
    "                m = n\n",
    "                recording = True\n",
    "    \n",
    "    # Capture the final series if still recording.\n",
    "    if recording and (n - m) > 1:\n",
    "        results.append(combo_frame[m:])\n",
    "    \n",
    "    print(\"returning {} timeseries\".format(len(results)))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the start/end times of each identified subseries. Since there are many of them, we print only the last result as a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_series = find_breaks(df, max_flats=5)\n",
    "for ss in split_series:\n",
    "    v = ss['timestamp'].values\n",
    "\n",
    "# Inserting this print statement into the for loop will print all timeseries\n",
    "print(\"    {0} - {1}\".format(v[0], v[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Segmented Timeseries\n",
    "\n",
    "The following function plots a single subseries of the quaternion tuple data and applies a color gradiant based on the associated time stamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_bokeh_panel(data, keyx, keyy, mapper=None):\n",
    "    \n",
    "    # Create a bokeh.plotting figure object.\n",
    "    n = bp.figure(height=400, width=400, match_aspect=True)\n",
    "    \n",
    "    # Add lines to make 0 axis a bit more obvious.\n",
    "    lw = 1.3\n",
    "    vline = Span(location=0, dimension='height', line_color='black', line_width=lw)\n",
    "    hline = Span(location=0, dimension='width', line_color='black', line_width=lw)\n",
    "    n.renderers.extend([vline, hline])\n",
    "    \n",
    "    # Add a circle plot of parameters with the color map applied.\n",
    "    radius = np.max([0.0025, (data[keyx].max() - data[keyy].min()) / 100])  # Standardize the radius of points\n",
    "    n.circle(source=data, x=keyx, y=keyy, fill_alpha=0.6, fill_color=mapper, line_color=None, radius=radius)\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "def plot_quaternion_color(data):\n",
    "    \"\"\"\n",
    "    Plot quaternion-vs-quaternion timeseries data with color mapping based on the timing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        A combined quaternion timeseries data set.\n",
    "    \"\"\"\n",
    "    \n",
    "    mjd = data['MJD']\n",
    "    n_ticks = 10\n",
    "\n",
    "    # Set up a linear color map based on the MJD data.\n",
    "    mapper = linear_cmap(field_name='MJD', palette=cm, low=min(mjd), high=max(mjd))\n",
    "    \n",
    "    # Create the bokeh.plotting figures:\n",
    "    fig_grid = []\n",
    "    for i in range(4):\n",
    "        fig_list = []\n",
    "        for j in range(4):\n",
    "            if i > j:\n",
    "                n = make_single_bokeh_panel(data, f\"value_{j+1}\", f\"value_{i+1}\", mapper=mapper)\n",
    "                \n",
    "                # Add some labels to our axes\n",
    "                n.xaxis.axis_label = f\"SCF_AC_SDR_QBJ_{j+1}\"\n",
    "                n.yaxis.axis_label = f\"SCF_AC_SDR_QBJ_{i+1}\"\n",
    "                fig_list.append(n)\n",
    "            else:\n",
    "                fig_list.append(None)\n",
    "        fig_grid.append(fig_list)\n",
    "\n",
    "    # Link ranges:\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if (fig_grid[i][j] is not None):\n",
    "                if j > 0:\n",
    "                    fig_grid[i][j].y_range = fig_grid[i][0].y_range\n",
    "                if i < 3:\n",
    "                    fig_grid[i][j].x_range = fig_grid[3][j].x_range\n",
    "        \n",
    "    p = gridplot(fig_grid, toolbar_location='left')\n",
    "    \n",
    "    # Translate legend values from MJD to time stamps.\n",
    "    indices = list(range(0, len(mjd), np.max([int(len(mjd)/n_ticks), 1])))\n",
    "    tick_dict = {mjd.values[x]: data['timestamp'].values[x] for x in indices}\n",
    "    ticks = FixedTicker(ticks=list(tick_dict.keys()))\n",
    "    \n",
    "    # Add a color bar legend for the MJD data.\n",
    "    color_bar = ColorBar(color_mapper=mapper['transform'], \n",
    "                         width=12,\n",
    "                         ticker=ticks,\n",
    "                         major_label_overrides=tick_dict,\n",
    "                         location=(0, 0), \n",
    "                         label_standoff=45,\n",
    "                         )\n",
    "    fig_grid[1][0].add_layout(color_bar, 'right')\n",
    "    \n",
    "    # Display the figure.\n",
    "    bp.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following command you can update the index to change which split timeseries you are plotting. Once the plot renders, use the plot control tools in the upper right to pan, zoom, and save the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quaternion_color(split_series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(split_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "* The [Roman Engineering Database Portal](https://mast.stsci.edu/edp/#/roman), with restricted access pre-launch.\n",
    "* The restricted-access [Roman Engineering Data](https://outerspace.stsci.edu/spaces/RAPD/pages/301172598/Search+for+Calibrated+Engineering+Data) tutorial in the Roman Pre-Launch documentation (on innerspace).  This information will be made public at a later date.\n",
    "\n",
    "## About this Notebook\n",
    "This notebook was developed by MAST staff, chiefly Sedona Price and Zach Claytor, based on the equivalent JWST EDB notebook.\n",
    "\n",
    "**Author(s):** Sedona Price and Zach Claytor, adapted from the [JWST EDB retrieval notebook](https://github.com/zclaytor/mast_notebooks/blob/main/notebooks/JWST/Engineering_Database_Retreival/EDB_Retrieval.ipynb) by MAST staff (chiefly Dick Shaw, Peter Forshay, and Bernie Shiao, with additional editing by Thomas Dutkiewicz). <br>\n",
    "**Keyword(s):** Tutorial, Roman <br>\n",
    "**First published:** Feb 2026 <br>\n",
    "**Last updated:** Feb 2026 \n",
    "\n",
    "***\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/style-guides/master/guides/images/stsci-logo.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "[Return to top of page](#Roman-Engineering-Data-Retrieval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
